## Functional Requirements

- Client wants to build a Japanese Language Learning solution where the students will be interacting with different study activities that will be generated by Generative AI model. 

- Client does not want to use cloud hosted models for this, they plan to invest $10k-15k for building a PC that can run a model and serve the presumed 500 user.

## Primary Assumptions
1. We are assuming that the open-source LLM that we choose can run on the infrastructure that we build within client's budget.
2. It is an assumption that the on-premise deployment of model will be able to handle the 500 users' load.


## Data Strategy
Client does not want to face any copyright infringement issues, so we have to purchase the teaching/vocabulary materials that we use and save it on our end in the database.

## Consideration
We plan to use IBM Granite as it is an open-source models and the training data used for the model are open. So it avoids any copyright concerns.


[Hugging Face Link for IBM Granite 3.1](https://huggingface.co/ibm-granite/granite-3.1-8b-instruct)

Model has 8 billion parameters. 